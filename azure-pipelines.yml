resources:
  repositories:
  - repository: azure-databricks-mlops # The name used to reference this repository in the checkout step
    type: github
    endpoint: laryxm
    name: laryxm/azure-databricks-mlops

variables:
- group: 'databricks'

trigger:
- master

# TRAIN (Build) Pipeline / CI
stages:
- stage: Train
  displayName: 'Train Model'
  jobs:
  - job: Train
    pool:
      vmImage: ubuntu-latest
    steps:
    - script: env | sort
      displayName: 'Environment / Context'
    - task: UsePythonVersion@0
      displayName: 'Use Python 3.7'
      inputs:
        versionSpec: 3.7

    - checkout: self
      persistCredentials: true
      clean: true
      displayName: 'Checkout & Build.Reason: $(Build.Reason) & Build.SourceBranchName: $(Build.SourceBranchName)'

    - script: |
        python -m pip install --upgrade databricks-cli
      displayName: 'Install dependencies'

    - script: |
            echo "Checking out the $(Build.SourceBranchName) branch"
            databricks repos update --path /Repos/QA/azure-databricks-mlops --branch "$(Build.SourceBranchName)"
      env:
        DATABRICKS_HOST: $(databricks-host-dev)
        DATABRICKS_TOKEN: $(databricks-token-dev)
      displayName: 'Update Staging environment'

    - script: |
          JOB_ID=$(databricks jobs create --json-file jobs/create-train-job.json | jq .job_id)
          RUN_ID=$(databricks jobs run-now --job-id $JOB_ID | jq '.run_id')

          job_status="PENDING"
            while [ $job_status = "RUNNING" ] || [ $job_status = "PENDING" ]
            do
              sleep 2
              job_status=$(databricks runs get --run-id $RUN_ID | jq -r '.state.life_cycle_state')
              echo Status $job_status
            done
      env:
        DATABRICKS_HOST: $(databricks-host-dev)
        DATABRICKS_TOKEN: $(databricks-token-dev)
      displayName: 'Train Model'
      
    - script: |
        JOB_ID=$(databricks jobs create --json-file jobs/register-model-qa-job.json | jq .job_id)
        RUN_ID=$(databricks jobs run-now --job-id $JOB_ID | jq '.run_id')

        job_status="PENDING"
          while [ $job_status = "RUNNING" ] || [ $job_status = "PENDING" ]
          do
            sleep 2
            job_status=$(databricks runs get --run-id $RUN_ID | jq -r '.state.life_cycle_state')
            echo Status $job_status
          done
      env:
        DATABRICKS_HOST: $(databricks-host-dev)
        DATABRICKS_TOKEN: $(databricks-token-dev)
      displayName: 'Register Model in DEV/QA'
      
    - script: |
        JOB_ID=$(databricks jobs create --json-file jobs/move-staging-job.json | jq .job_id)
        RUN_ID=$(databricks jobs run-now --job-id $JOB_ID | jq '.run_id')

        job_status="PENDING"
          while [ $job_status = "RUNNING" ] || [ $job_status = "PENDING" ]
          do
            sleep 2
            job_status=$(databricks runs get --run-id $RUN_ID | jq -r '.state.life_cycle_state')
            echo Status $job_status
          done
      env:
        DATABRICKS_HOST: $(databricks-host-dev)
        DATABRICKS_TOKEN: $(databricks-token-dev)
      displayName: 'Transition to Staging'

- stage: DeployProd
  displayName: 'Deploy Model to Production'
  jobs:
  - deployment: prod_deploy
    displayName: 'Deploy Model'
    pool:
      vmImage: ubuntu-latest
    environment: 'deploy-prod'
    strategy:
      runOnce:
        deploy:
          steps:
          - checkout: azure-databricks-mlops
          - script: |
              python -m pip install --upgrade databricks-cli
              python -m pip install --upgrade mlflow
            displayName: 'Install Dependencies'
          - script: |
                  echo "Checking out the $(Build.SourceBranchName) branch"
                  databricks repos update --path /Repos/Prod/azure-databricks-mlops --branch "$(Build.SourceBranchName)"
            env:
              DATABRICKS_HOST: $(databricks-host-prod)
              DATABRICKS_TOKEN: $(databricks-token-prod)
            displayName: 'Update Production environment'
          - script: 'python scripts/download-artifacts.py'
            displayName: 'Download Artifacts from DEV/QA'
            env:
              DATABRICKS_HOST: $(databricks-host-dev)
              DATABRICKS_TOKEN: $(databricks-token-dev)
          - script: 'python scripts/upload-artifacts.py'
            displayName: 'Log Artifacts on Production'
            env:
              DATABRICKS_HOST: $(databricks-host-prod)
              DATABRICKS_TOKEN: $(databricks-token-prod)
          - script: |
              JOB_ID=$(databricks jobs create --json-file jobs/register-model-prod-job.json | jq .job_id)
              RUN_ID=$(databricks jobs run-now --job-id $JOB_ID | jq '.run_id')

              job_status="PENDING"
                while [ $job_status = "RUNNING" ] || [ $job_status = "PENDING" ]
                do
                  sleep 2
                  job_status=$(databricks runs get --run-id $RUN_ID | jq -r '.state.life_cycle_state')
                  echo Status $job_status
                done
            displayName: 'Register Model in Prod'
            env:
              DATABRICKS_HOST: $(databricks-host-prod)
              DATABRICKS_TOKEN: $(databricks-token-prod)
          - script: |
              JOB_ID=$(databricks jobs create --json-file jobs/score-job.json | jq .job_id)
              RUN_ID=$(databricks jobs run-now --job-id $JOB_ID | jq '.run_id')
              
              job_status="PENDING"
              
              while [ $job_status = "RUNNING" ] || [ $job_status = "PENDING" ]
              do
                  sleep 2
                  job_status=$(databricks runs get --run-id $RUN_ID | jq -r '.state.life_cycle_state')
                  echo Status $job_status
              done
            displayName: 'Create and Run Score Job'
            env:
              DATABRICKS_HOST: $(databricks-host-prod)
              DATABRICKS_TOKEN: $(databricks-token-prod)
