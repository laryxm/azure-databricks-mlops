# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

trigger:
- master

pool:
  vmImage: 'ubuntu-latest'

stages:
- stage: Build
  jobs:
  - job: train
    displayName: Train model
    steps:
    - task: UsePythonVersion@0
      displayName: Use Python 3.7.*
      inputs:
        versionSpec: 3.7.*
    - task: riserrad.azdo-databricks.azdo-databricks-configuredatabricks.configuredatabricks@0
      displayName: 'Configure Databricks Cluster'
      inputs:
        url: $(databricks-url)
        token: $(databricks-token)
    - task: riserrad.azdo-databricks.azdo-databricks-executenotebook.executenotebook@0
      displayName: Train
      inputs:
        notebookPath: /Shared/train
        existingClusterId: $(databricks-cluster-id)
    - task: riserrad.azdo-databricks.azdo-databricks-waitexecution.waitexecution@0
      displayName: 'Wait for Notebook execution'
    - task: riserrad.azdo-databricks.azdo-databricks-executenotebook.executenotebook@0
      displayName: Unit tests
      inputs:
        notebookPath: /Shared/tests
        existingClusterId: $(databricks-cluster-id)
    - task: riserrad.azdo-databricks.azdo-databricks-waitexecution.waitexecution@0
      displayName: 'Wait for Notebook execution'